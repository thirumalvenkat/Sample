{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grp2-capstone-gl-part2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gocyt_UoU5b1",
        "BV4vh8E1V0kn",
        "O65N_v_vV6tE"
      ],
      "authorship_tag": "ABX9TyPp7/Uoo11qwCzqnaB7h52H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thirumalvenkat/Sample/blob/master/grp2_capstone_gl_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6IW8t5AUvQv",
        "colab_type": "text"
      },
      "source": [
        "### Notebook is created and owned by Capstone Group 2 of Great Learnings Class of August2019/AI/ML. Confidential and cannot be shared with anyone and rights owned by the following members\n",
        "\n",
        "1.   Thirumalvalavan Venkatesan thirumal.valavan@gmail.com \n",
        "2.   Sundaresan Mooorthy \n",
        "1.   Vivek Suresh\n",
        "2.   Muthu Govindraraj\n",
        "1.   Riaz\n",
        "2.   Prasanna Dravidamani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gocyt_UoU5b1",
        "colab_type": "text"
      },
      "source": [
        "## 01 Google Cloud Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHndABy6UsAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0edb67c3-9db8-4a4a-8aa7-9354c07b1b46"
      },
      "source": [
        "%env PROJECT_ID = stately-planet-181816\n",
        "#Set the Project Id\n",
        "!gcloud config set project $PROJECT_ID\n",
        "\n",
        "#Authenticate the project\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth as google_auth\n",
        "  google_auth.authenticate_user()\n",
        "else:\n",
        "  %env GOOGLE_APPLICATION_CREDENTIALS ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PROJECT_ID=stately-planet-181816\n",
            "Updated property [core/project].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHR7kIxcUsbh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7mHZ3rQg4Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set the variables for bucket and Zone\n",
        "%env BUCKET_NAME = grp2-capstone-gl\n",
        "%env REGION = us-central1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV4vh8E1V0kn",
        "colab_type": "text"
      },
      "source": [
        "## 02 Import required packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzN2Ss72hsJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing import image as keras_image\n",
        "import os\n",
        "import numpy as np\n",
        "from IPython.display import display, Image\n",
        "import PIL\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import time\n",
        "import pickle\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "# All Keras Packages and backends\n",
        "#import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "#from keras_yolo3.yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "#from keras_yolo3.yolo3.utils import get_random_data\n",
        "from keras_frcnn import config, data_generators\n",
        "from keras_frcnn import losses as losses\n",
        "import keras_frcnn.roi_helpers as roi_helpers\n",
        "from keras.utils import generic_utils\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O65N_v_vV6tE",
        "colab_type": "text"
      },
      "source": [
        "## 03 Mount the Google Cloud Storage Bucket using GCSFUSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKGDCKGOi2Ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls gs://$BUCKET_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Nwe4r5kh-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pGJ8Ifwxlkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu-nr6YYxsEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o8Hh4qyMGRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMk3JuvsMYnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 grp2-capstone-gl data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cN62UZuNKVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -ltr /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9HMb69WDs1",
        "colab_type": "text"
      },
      "source": [
        "## 04 Exploratory Data Analysis \n",
        "Read the Logo27 datasets from GCS bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_jH70DRfKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -ltr /content/data/flickr_logos_27_dataset_images/ | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh7R3SeBYKid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = \"/content/data/flickr_logos_27_dataset_images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdCsxkCepRAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train = len(os.listdir(train_data))\n",
        "sample_idxs = np.random.choice(n_train, 5, replace=False)\n",
        "\n",
        "#First Time Trying Ipython to Display the Images. I will do it through other means also. \n",
        "for idx in sample_idxs:\n",
        "  filename = os.listdir(train_data)[idx]\n",
        "  image = Image(os.path.join(train_data, filename))\n",
        "  display(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxfrnN5upUlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "widths, heights = [], []\n",
        "width_min, width_max = np.inf, -np.inf\n",
        "height_min, height_max = np.inf, -np.inf\n",
        "for filename in os.listdir(train_data):\n",
        "  image = PIL.Image.open(os.path.join(train_data, filename))\n",
        "  widths.append(image.size[0]) # width\n",
        "  heights.append(image.size[1]) # height\n",
        "# Print out stats for viewing pleasure.\n",
        "print('Training data average (width, height): ', (np.mean(widths), np.mean(heights)))\n",
        "print('Training data (minimum width, maximum width): ', (np.min(widths), np.max(widths)))\n",
        "print('Training data (minimum height, maximum height): ', (np.min(heights), np.max(heights)))\n",
        "print('Training data (STD of widths, STD of heights): ', (np.std(widths), np.std(heights)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjWMWz0P2wRb",
        "colab_type": "text"
      },
      "source": [
        "## 05 Labels Validation and EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVzqjzxxqLFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colnames=[\"filename\", \"label\",\"subset\",\"x1\",\"y1\",\"x2\",\"y2\"]\n",
        "labels_directory=\"/content/data/flickr_logos_27_dataset/\"\n",
        "labels_file=\"flickr_logos_27_dataset_training_set_annotation.txt\"\n",
        "logo_labels = pd.read_csv(\"{}/{}\".format(labels_directory,labels_file),header=0,names=colnames, sep=r\"\\s+\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs78vlfvtvKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logo_labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22bf98II9qxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logo_labels[(logo_labels['filename'] == '4763210295.jpg') & (logo_labels['subset'] == 1)]\n",
        "#logo_labels[(logo_labels['subset'] == 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXl28e0L-kN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_file=\"4763210295.jpg\"\n",
        "image = Image(os.path.join(train_data, temp_file))\n",
        "display(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmHB5ZN-vLVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logo_labels.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niwVkRjG6ltR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_files_grp = logo_labels.groupby('filename').count()\n",
        "label_files_count = label_files_grp['label'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAt8xLcf2RtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_logos = logo_labels['label'].value_counts()\n",
        "num_logos_gp = logo_labels.groupby('label').count()\n",
        "num_logos_count = num_logos.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVurPBCk23Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Logos Count:\",num_logos)\n",
        "print(\"Number of Logos in the Dataset:\",num_logos_count)\n",
        "print(\"Total Number of files:\",label_files_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mhygRvl275q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = logo_labels['label'].hist(figsize=(16, 8), bins=120, xrot=90, xlabelsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ2TvwR53LCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "logo_labels['label'] = le.fit_transform(logo_labels['label'])\n",
        "train_labels = keras.utils.to_categorical(logo_labels['label'], num_classes=num_logos_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WjayoSov1Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEBA0sOvuDB9",
        "colab_type": "text"
      },
      "source": [
        "## 06 Prepare Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0CHoQrRuZEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize all the variables\n",
        "img_rows = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udFsTId0wz60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images(input_size,file_name,tgt_size,labels):\n",
        "  all_images=[]\n",
        "  # Start time\n",
        "  start_time = time.time()\n",
        "  for i in range(input_size):\n",
        "    # Set the Path\n",
        "    path = labels.iloc[i].filename\n",
        "    path = os.path.join(train_data,path)\n",
        "    #Read the files usign Keras\n",
        "    img  = keras_image.load_img(path,target_size=(tgt_size,tgt_size))\n",
        "    #Resize the images\n",
        "    img_array = keras_image.img_to_array(img)\n",
        "    #Just Print the status for monitoring\n",
        "    if (i%200) == 0:\n",
        "      print(i)\n",
        "    all_images.append(img_array)\n",
        "    #End For Loop  \n",
        "  end_time = time.time()\n",
        "  # Difference between start and end-times.\n",
        "  time_dif = end_time - start_time\n",
        "  # Print the time-usage.\n",
        "  pickle.dump(all_images, open( file_name + '.p', \"wb\" ) )\n",
        "  print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
        "  return all_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFIM7E2sy-n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_images = load_images(n_train,'train_load_images',img_rows,logo_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGPE_rpc0HHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir /content/data/artefacts\n",
        "#!mv 'train_load_images.p' /content/data/artefacts/train_load_new_images.p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Funzf2OR5Y0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load TRAIN\n",
        "train_images = pickle.load(open(\"/content/data/artefacts/train_load_new_images.p\", \"rb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azngLzMM9Cnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of Train Images:\",np.shape(train_images))\n",
        "print(\"Shape of Train Labels:\",np.shape(train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9SaiMCQ5y6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_f_images = np.array(train_images)\n",
        "train_f_images = train_f_images/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rvJR22D79Br",
        "colab_type": "text"
      },
      "source": [
        "## 07 Train and Validation Split\n",
        "Might not be needed if we figure out the test datasets separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFYrTRYl75g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainx_images,val_images, trainx_labels, val_labels = train_test_split(train_f_images, train_labels, test_size = 0.2, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2T4UzS8MQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}